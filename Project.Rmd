---
title: "Getting and Cleaning Data "
author: "Aravind"
date: "March 16, 2018"
output: md_document
---

Human Activity Recognition Using Smartphones Dataset Version 1.0
======================================================================

Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2) 1 - Smartlab - Non-Linear Complex Systems Laboratory DITEN - Università degli Studi di Genova, Genoa (I-16145), Italy. 2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living Universitat Politècnica de Catalunya (BarcelonaTech). Vilanova i la Geltrú (08800), Spain activityrecognition '@' smartlab.ws

=============================================================================================


### Dataset Description

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details.

For each record it is provided:

* Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
* Triaxial Angular velocity from the gyroscope.
* A 561-feature vector with time and frequency domain variables.
* Its activity label.
* An identifier of the subject who carried out the experiment.

The dataset includes the following files:

* 'README.txt'

* 'features_info.txt': Shows information about the variables used on the feature vector.

* 'features.txt': List of all features.

* 'activity_labels.txt': Links the class labels with their activity name.

* 'train/X_train.txt': Training set.

* 'train/y_train.txt': Training labels.

* 'test/X_test.txt': Test set.

* 'test/y_test.txt': Test labels.

The following files are available for the train and test data. Their descriptions are equivalent.

* 'train/subject_train.txt': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30.

* 'train/Inertial Signals/total_acc_x_train.txt': The acceleration signal from the smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element vector. The same description applies for the 'total_acc_x_train.txt' and 'total_acc_z_train.txt' files for the Y and Z axis.

* 'train/Inertial Signals/body_acc_x_train.txt': The body acceleration signal obtained by subtracting the gravity from the total acceleration.

* 'train/Inertial Signals/body_gyro_x_train.txt': The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second.

### Feature Selection

The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz.

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag).

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals).

These signals were used to estimate variables of the feature vector for each pattern:
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

tBodyAcc-XYZ tGravityAcc-XYZ tBodyAccJerk-XYZ tBodyGyro-XYZ tBodyGyroJerk-XYZ tBodyAccMag tGravityAccMag tBodyAccJerkMag tBodyGyroMag tBodyGyroJerkMag fBodyAcc-XYZ fBodyAccJerk-XYZ fBodyGyro-XYZ fBodyAccMag fBodyAccJerkMag fBodyGyroMag fBodyGyroJerkMag

The set of variables that were estimated from these signals are:

mean(): Mean value std(): Standard deviation mad(): Median absolute deviation max(): Largest value in array min(): Smallest value in array sma(): Signal magnitude area energy(): Energy measure. Sum of the squares divided by the number of values. iqr(): Interquartile range entropy(): Signal entropy arCoeff(): Autorregresion coefficients with Burg order equal to 4 correlation(): correlation coefficient between two signals maxInds(): index of the frequency component with largest magnitude meanFreq(): Weighted average of the frequency components to obtain a mean frequency skewness(): skewness of the frequency domain signal kurtosis(): kurtosis of the frequency domain signal bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window. angle(): Angle between to vectors.

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:

gravityMean tBodyAccMean tBodyAccJerkMean tBodyGyroMean tBodyGyroJerkMean

The complete list of variables of each feature vector is available in 'features.txt'

### Notes:

Features are normalized and bounded within [-1,1].
Each feature vector is a row on the text file.
The units used for the accelerations (total and body) are 'g's (gravity of earth -> 9.80665 m/seg2).
The gyroscope units are rad/seg.
A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: http://www.youtube.com/watch?v=XOEN9W05_4A
For more information about this dataset please contact: activityrecognition '@' smartlab.ws


## 1. Loading and pre-processing the dataset

```{r}
## Packages required
library(reshape2)
library(data.table)

## Download file from UCI and unzip the file
download.file("http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip", "sp.zip")
zipF<-file.choose() # lets you choose a file and save its file path in R (at least for windows)
outDir<-"smartphones" # Define the folder where the zip file should be unzipped to 
unzip(zipF,exdir=outDir)
```

### Loading the feature table

```{r}
feature <- read.table(".//smartphones//UCI HAR Dataset//features.txt")[,2]
length(feature)
```

### Extracting feature containg mean and std column names

```{r}
extract_feature <- grepl("mean|std", feature) 
```

### Loading activity dataset consisting of activity labels.

```{r}
activity <- read.table(".//smartphones//UCI HAR Dataset//activity_labels.txt")[,2]
head(activity)
```

### Loading the testing dataset

```{r}
x_test <- read.table(".//smartphones//UCI HAR Dataset//test//X_test.txt")
dim(x_test)
y_test <- read.table(".//smartphones//UCI HAR Dataset//test//Y_test.txt")
subject_test <- read.table(".//smartphones//UCI HAR Dataset//test//subject_test.txt")
head(subject_test)
names(x_test) = feature
```

The x_test consists of 561 attributes. The analysis depends on mean and std columns. So, updating x_test, so that it contains only the mean and std columns.

```{r}
x_test <- x_test[,extract_feature]

## Naming labels for test set

y_test[,2] = activity[y_test[,1]]
names(y_test) <- c("ID", "Label")
names(y_test)
names(subject_test) <- "Subject"
```

### Combining all the test tables to a single data frame.

```{r}
test <- cbind(as.data.table(subject_test), y_test, x_test)
names(test)
```

### Reading training set data

```{r}
x_train <- read.table(".//smartphones//UCI HAR Dataset//train//X_train.txt")
y_train <- read.table(".//smartphones//UCI HAR Dataset//train//Y_train.txt")
subject_train <- read.table(".//smartphones//UCI HAR Dataset//train//subject_train.txt")

## Naming x_train columns
names(x_train) <- feature

## Updating x_train so that it only contains meand and std col names
x_train <- x_train[,extract_feature]

## Naming labels for training set
y_train[,2] <- activity[y_train[,1]]
names(y_train) <- c("ID", "Label")
names(subject_train) <- "Subject"
```

### Merging all the train tables into a single table

```{r}
train <- cbind(as.data.frame(subject_train), y_train,x_train)
dim(train)
```

### Merging test and train data 

```{r}
tidy_data <- rbind(test,train)
dim(tidy_data)
variables = names(tidy_data[,-c("Subject","ID","Label")])
melt_data = melt(tidy_data, id = c("Subject","ID","Label"), measure.vars = variables)
head(tidy_data,2)
dim(melt_data)
```

## Finding average of all values using dcast

```{r}
tidy_data2 <- dcast(melt_data, Subject + Label ~ variable,mean)
head(tidy_data2, 2)
dim(tidy_data2)
```

The dataset is tidy and cleaned which can be used for the analysis.






